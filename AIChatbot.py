import streamlit as st
import os
from dotenv import load_dotenv
from operator import itemgetter
from typing import List, Tuple, Dict, Any
from pinecone import Pinecone
from langchain_anthropic import ChatAnthropic
from langchain_openai import OpenAIEmbeddings  # OpenAI ì„ë² ë”©ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough
from langchain_pinecone import PineconeVectorStore
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import time

# API í‚¤ ì„¤ì • (Streamlit secretsì—ì„œ ê°€ì ¸ì˜´)
os.environ["ANTHROPIC_API_KEY"] = st.secrets["anthropic_api_key"]
os.environ["OPENAI_API_KEY"] = st.secrets["openai_api_key"]
os.environ["PINECONE_API_KEY"] = st.secrets["pinecone_api_key"]

# ModifiedPineconeVectorStore í´ë˜ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€

def main():
    st.title("ğŸ¤Conference Q&A System")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "mode" not in st.session_state:
        st.session_state.mode = "Report Mode"

    # Pinecone ì´ˆê¸°í™”
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    index_name = "conference"
    index = pc.Index(index_name)

    # Claude ëª¨ë¸ ì„ íƒ
    if "claude_model" not in st.session_state:
        st.session_state.claude_model = "claude-3-opus-20240229"

    st.session_state.claude_model = st.selectbox(
        "Select Claude model:",
        ("claude-3-opus-20240229", "claude-3-sonnet-20240229"),
        index=("claude-3-opus-20240229", "claude-3-sonnet-20240229").index(st.session_state.claude_model)
    )
    llm = ChatAnthropic(model=st.session_state.claude_model)

    # Pinecone ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •
    vectorstore = ModifiedPineconeVectorStore(
        index=index,
        embedding=OpenAIEmbeddings(model="text-embedding-ada-002"),
        text_key="source"
    )

    # ê²€ìƒ‰ê¸° ì„¤ì •
    retriever = vectorstore.as_retriever(
        search_type='mmr',
        search_kwargs={"k": 10, "fetch_k": 20, "lambda_mult": 0.7}
    )

    # ë¦¬í¬íŠ¸ ëª¨ë“œìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
    report_template = """
    Human: Please provide a comprehensive report based on the following question and context. Use the style of Harvard Business Review (HBR) and follow these guidelines:

    Question: {question}
    Context: {context}

    Guidelines:
    1. Start with a conference overview, explaining the context and main themes.
    2. Analyze key content from the conference, categorizing it into topics, facts, and your opinions.
    3. Conclude with new trends, insights, and 3 follow-up questions with brief answers.
    4. Use clear and concise business writing targeted at executives.
    5. Answer in Korean and provide rich sentences to enhance the quality of the answer.
    6. Adhere to these length constraints: Conference Overview (ì•½ 4000 ë‹¨ì–´), Contents (ì•½ 7000 ë‹¨ì–´), Conclusion (ì•½ 4000 ë‹¨ì–´).

    Assistant: ë„¤, ì£¼ì–´ì§„ ì§€ì¹¨ì— ë”°ë¼ ì»¨í¼ëŸ°ìŠ¤ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.

    Human: ì´ì œ ìœ„ì˜ ì§€ì¹¨ì— ë”°ë¼ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

    Assistant: [ë³´ê³ ì„œ ë‚´ìš©]

    Human: ê°ì‚¬í•©ë‹ˆë‹¤. ì´ì œ ì±—ë´‡ ëª¨ë“œë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ì‘ë‹µì„ ìƒì„±í•´ ì£¼ì„¸ìš”. ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

    Question: {question}
    Context: {context}

    Assistant: ë„¤, ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ë‹¨í•œ ì‘ë‹µì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.

    [ì±—ë´‡ ì‘ë‹µ ë‚´ìš©]
    """
    report_prompt = ChatPromptTemplate.from_template(report_template)

    # ì±—ë´‡ ëª¨ë“œìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
    chatbot_template = """
    Human: ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•½ 4,000ìë¡œ ëŒ€í™”ì²´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

    Question: {question}
    Context: {context}

    Assistant: ë„¤, ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•½ 4,000ì ë¶„ëŸ‰ì˜ ëŒ€í™”ì²´ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.

    [ì±—ë´‡ ì‘ë‹µ ë‚´ìš©]
    """
    chatbot_prompt = ChatPromptTemplate.from_template(chatbot_template)

    # format_docs í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€

    def get_report_chain(prompt):
        answer = prompt | llm | StrOutputParser()
        return (
            RunnableParallel(question=RunnablePassthrough(), docs=retriever)
            .assign(context=format)
            .assign(answer=answer)
            .pick(["answer", "docs"])
        )

    def get_chatbot_chain(prompt):
        answer = prompt | llm | StrOutputParser()
        return (
            RunnableParallel(question=RunnablePassthrough(), docs=retriever)
            .assign(context=format)
            .assign(answer=answer)
            .pick("answer")
        )

    report_chain = get_report_chain(report_prompt)
    chatbot_chain = get_chatbot_chain(chatbot_prompt)

    # ëª¨ë“œ ì„ íƒ ë° ëŒ€í™” ê¸°ë¡ í‘œì‹œ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€

    # ì‚¬ìš©ì ì…ë ¥ ë° ì‘ë‹µ ìƒì„± ë¶€ë¶„
    if question := st.chat_input("ì»¨í¼ëŸ°ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”:"):
        # ë¦¬ì…‹ í‚¤ì›Œë“œ í™•ì¸ ë° ëŒ€í™” ì´ˆê¸°í™” ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€

        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        with st.chat_message("assistant"):
            # ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±
            status_placeholder = st.empty()
            progress_bar = st.progress(0)

            try:
                # ì¿¼ë¦¬ ì²˜ë¦¬, ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰, ë‹µë³€ ìƒì„±, ì‘ë‹µ ë§ˆë¬´ë¦¬ ë‹¨ê³„ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                # ë‹¨, chain ì„ íƒ ë¶€ë¶„ë§Œ ìˆ˜ì •
                chain = report_chain if st.session_state.mode == "Report Mode" else chatbot_chain
                response = chain.invoke(question)

                # ë‹µë³€ í‘œì‹œ
                answer = response['answer'] if st.session_state.mode == "Report Mode" else response
                st.markdown(answer)

                # ì†ŒìŠ¤ í‘œì‹œ (ë¦¬í¬íŠ¸ ëª¨ë“œë§Œ)
                if st.session_state.mode == "Report Mode":
                    with st.expander("Sources"):
                        for doc in response['docs']:
                            st.write(f"- {doc.metadata['source']}")

                # ëŒ€í™” ê¸°ë¡ì— ë„ìš°ë¯¸ ì‘ë‹µ ì¶”ê°€
                st.session_state.messages.append({"role": "assistant", "content": answer})

            finally:
                # ìƒíƒœ í‘œì‹œ ì œê±°
                status_placeholder.empty()
                progress_bar.empty()

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        reset_conversation()

if __name__ == "__main__":
    main()
